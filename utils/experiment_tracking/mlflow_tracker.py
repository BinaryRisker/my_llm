"""
MLflowå®éªŒè·Ÿè¸ªå™¨
===============

é›†æˆMLflowè¿›è¡Œå®éªŒè·Ÿè¸ªå’Œç®¡ç†ï¼š
- è‡ªåŠ¨è®°å½•è®­ç»ƒå‚æ•°ã€æŒ‡æ ‡å’Œæ¨¡å‹
- æ”¯æŒå®éªŒæ¯”è¾ƒå’Œå¯è§†åŒ–
- æ¨¡å‹ç‰ˆæœ¬ç®¡ç†å’Œéƒ¨ç½²
- ä¸ç°æœ‰è®­ç»ƒæµç¨‹æ— ç¼é›†æˆ

ä½¿ç”¨æ–¹æ³•:
    from utils.experiment_tracking.mlflow_tracker import MLflowTracker
    
    tracker = MLflowTracker(experiment_name="my_experiment")
    
    with tracker.start_run():
        tracker.log_params({"lr": 0.001, "batch_size": 32})
        tracker.log_metric("loss", 0.5, step=100)
        tracker.log_model(model, "transformer_model")
"""

import os
import json
import tempfile
from pathlib import Path
from typing import Dict, Any, Optional, Union, List
import logging
import contextlib
from datetime import datetime

try:
    import mlflow
    import mlflow.pytorch
    import mlflow.sklearn
    from mlflow import MlflowClient
    from mlflow.entities import RunStatus
    MLFLOW_AVAILABLE = True
except ImportError:
    MLFLOW_AVAILABLE = False
    mlflow = None

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    torch = None

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MLflowTracker:
    """MLflowå®éªŒè·Ÿè¸ªå™¨"""
    
    def __init__(self,
                 experiment_name: str = "default_experiment",
                 tracking_uri: Optional[str] = None,
                 registry_uri: Optional[str] = None,
                 artifact_location: Optional[str] = None,
                 run_name: Optional[str] = None,
                 tags: Optional[Dict[str, str]] = None,
                 auto_log: bool = True):
        """
        åˆå§‹åŒ–MLflowè·Ÿè¸ªå™¨
        
        Args:
            experiment_name: å®éªŒåç§°
            tracking_uri: MLflow tracking server URI
            registry_uri: æ¨¡å‹æ³¨å†ŒURI
            artifact_location: artifactå­˜å‚¨ä½ç½®
            run_name: è¿è¡Œåç§°
            tags: è¿è¡Œæ ‡ç­¾
            auto_log: æ˜¯å¦å¼€å¯è‡ªåŠ¨æ—¥å¿—è®°å½•
        """
        if not MLFLOW_AVAILABLE:
            raise ImportError("MLflowæœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install mlflow")
        
        self.experiment_name = experiment_name
        self.run_name = run_name
        self.tags = tags or {}
        self.auto_log = auto_log
        
        # è®¾ç½®MLflowé…ç½®
        if tracking_uri:
            mlflow.set_tracking_uri(tracking_uri)
        
        if registry_uri:
            mlflow.set_registry_uri(registry_uri)
        
        # åˆ›å»ºæˆ–è·å–å®éªŒ
        try:
            self.experiment_id = mlflow.create_experiment(
                name=experiment_name,
                artifact_location=artifact_location
            )
            logger.info(f"åˆ›å»ºæ–°å®éªŒ: {experiment_name}")
        except Exception:
            experiment = mlflow.get_experiment_by_name(experiment_name)
            self.experiment_id = experiment.experiment_id
            logger.info(f"ä½¿ç”¨ç°æœ‰å®éªŒ: {experiment_name}")
        
        # MLflowå®¢æˆ·ç«¯
        self.client = MlflowClient()
        
        # å½“å‰è¿è¡Œ
        self.current_run = None
        self.run_id = None
        
        # å¯ç”¨è‡ªåŠ¨æ—¥å¿—è®°å½•
        if self.auto_log:
            self._setup_auto_logging()
    
    def _setup_auto_logging(self):
        """è®¾ç½®è‡ªåŠ¨æ—¥å¿—è®°å½•"""
        try:
            if TORCH_AVAILABLE:
                mlflow.pytorch.autolog()
            mlflow.sklearn.autolog()
            logger.info("å·²å¯ç”¨MLflowè‡ªåŠ¨æ—¥å¿—è®°å½•")
        except Exception as e:
            logger.warning(f"è®¾ç½®è‡ªåŠ¨æ—¥å¿—è®°å½•å¤±è´¥: {e}")
    
    @contextlib.contextmanager
    def start_run(self, 
                  run_name: Optional[str] = None,
                  nested: bool = False,
                  tags: Optional[Dict[str, str]] = None):
        """
        å¼€å§‹æ–°çš„MLflowè¿è¡Œ
        
        Args:
            run_name: è¿è¡Œåç§°
            nested: æ˜¯å¦åµŒå¥—è¿è¡Œ
            tags: è¿è¡Œæ ‡ç­¾
        """
        run_name = run_name or self.run_name
        run_tags = {**self.tags, **(tags or {})}
        
        # æ·»åŠ é»˜è®¤æ ‡ç­¾
        run_tags.update({
            "start_time": datetime.now().isoformat(),
            "python_version": str(os.sys.version_info[:2]),
        })
        
        try:
            with mlflow.start_run(
                experiment_id=self.experiment_id,
                run_name=run_name,
                nested=nested,
                tags=run_tags
            ) as run:
                self.current_run = run
                self.run_id = run.info.run_id
                
                logger.info(f"å¼€å§‹MLflowè¿è¡Œ: {run.info.run_id}")
                
                yield self
                
        finally:
            self.current_run = None
            self.run_id = None
            logger.info("MLflowè¿è¡Œå·²ç»“æŸ")
    
    def log_param(self, key: str, value: Any) -> None:
        """è®°å½•å‚æ•°"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_param(key, value)
    
    def log_params(self, params: Dict[str, Any]) -> None:
        """æ‰¹é‡è®°å½•å‚æ•°"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_params(params)
        logger.info(f"è®°å½•å‚æ•°: {list(params.keys())}")
    
    def log_metric(self, key: str, value: float, step: Optional[int] = None) -> None:
        """è®°å½•æŒ‡æ ‡"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_metric(key, value, step)
    
    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
        """æ‰¹é‡è®°å½•æŒ‡æ ‡"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_metrics(metrics, step)
        logger.info(f"è®°å½•æŒ‡æ ‡: {list(metrics.keys())}")
    
    def log_artifact(self, local_path: str, artifact_path: Optional[str] = None) -> None:
        """è®°å½•æ–‡ä»¶artifact"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_artifact(local_path, artifact_path)
        logger.info(f"è®°å½•artifact: {local_path}")
    
    def log_artifacts(self, local_dir: str, artifact_path: Optional[str] = None) -> None:
        """è®°å½•ç›®å½•artifacts"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_artifacts(local_dir, artifact_path)
        logger.info(f"è®°å½•artifactsç›®å½•: {local_dir}")
    
    def log_text(self, text: str, artifact_file: str) -> None:
        """è®°å½•æ–‡æœ¬å†…å®¹"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_text(text, artifact_file)
        logger.info(f"è®°å½•æ–‡æœ¬: {artifact_file}")
    
    def log_dict(self, dictionary: Dict[str, Any], artifact_file: str) -> None:
        """è®°å½•å­—å…¸å†…å®¹"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_dict(dictionary, artifact_file)
        logger.info(f"è®°å½•å­—å…¸: {artifact_file}")
    
    def log_figure(self, figure, artifact_file: str) -> None:
        """è®°å½•å›¾è¡¨"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.log_figure(figure, artifact_file)
        logger.info(f"è®°å½•å›¾è¡¨: {artifact_file}")
    
    def log_model(self, 
                  model,
                  artifact_path: str,
                  conda_env: Optional[str] = None,
                  signature: Optional[Any] = None,
                  input_example: Optional[Any] = None,
                  registered_model_name: Optional[str] = None) -> None:
        """
        è®°å½•æ¨¡å‹
        
        Args:
            model: æ¨¡å‹å¯¹è±¡
            artifact_path: artifactè·¯å¾„
            conda_env: Condaç¯å¢ƒæ–‡ä»¶
            signature: æ¨¡å‹ç­¾å
            input_example: è¾“å…¥æ ·ä¾‹
            registered_model_name: æ³¨å†Œæ¨¡å‹åç§°
        """
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        try:
            if TORCH_AVAILABLE and hasattr(model, 'state_dict'):
                # PyTorchæ¨¡å‹
                mlflow.pytorch.log_model(
                    pytorch_model=model,
                    artifact_path=artifact_path,
                    conda_env=conda_env,
                    signature=signature,
                    input_example=input_example,
                    registered_model_name=registered_model_name
                )
            else:
                # å…¶ä»–ç±»å‹æ¨¡å‹ï¼Œä½¿ç”¨é€šç”¨æ–¹æ³•
                mlflow.log_artifact(model, artifact_path)
            
            logger.info(f"è®°å½•æ¨¡å‹: {artifact_path}")
            
        except Exception as e:
            logger.error(f"è®°å½•æ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def log_training_progress(self, 
                            epoch: int,
                            train_loss: float,
                            val_loss: Optional[float] = None,
                            train_metrics: Optional[Dict[str, float]] = None,
                            val_metrics: Optional[Dict[str, float]] = None) -> None:
        """
        è®°å½•è®­ç»ƒè¿›åº¦
        
        Args:
            epoch: å½“å‰epoch
            train_loss: è®­ç»ƒæŸå¤±
            val_loss: éªŒè¯æŸå¤±
            train_metrics: è®­ç»ƒæŒ‡æ ‡
            val_metrics: éªŒè¯æŒ‡æ ‡
        """
        # è®°å½•æŸå¤±
        self.log_metric("train_loss", train_loss, step=epoch)
        if val_loss is not None:
            self.log_metric("val_loss", val_loss, step=epoch)
        
        # è®°å½•è®­ç»ƒæŒ‡æ ‡
        if train_metrics:
            for metric_name, value in train_metrics.items():
                self.log_metric(f"train_{metric_name}", value, step=epoch)
        
        # è®°å½•éªŒè¯æŒ‡æ ‡
        if val_metrics:
            for metric_name, value in val_metrics.items():
                self.log_metric(f"val_{metric_name}", value, step=epoch)
    
    def set_tag(self, key: str, value: str) -> None:
        """è®¾ç½®æ ‡ç­¾"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.set_tag(key, value)
    
    def set_tags(self, tags: Dict[str, str]) -> None:
        """æ‰¹é‡è®¾ç½®æ ‡ç­¾"""
        if not self.current_run:
            raise RuntimeError("æ²¡æœ‰æ´»è·ƒçš„MLflowè¿è¡Œï¼Œè¯·ä½¿ç”¨start_run()ä¸Šä¸‹æ–‡ç®¡ç†å™¨")
        
        mlflow.set_tags(tags)
        logger.info(f"è®¾ç½®æ ‡ç­¾: {list(tags.keys())}")
    
    def end_run(self, status: str = "FINISHED") -> None:
        """ç»“æŸå½“å‰è¿è¡Œ"""
        if self.current_run:
            mlflow.end_run(status)
            logger.info(f"ç»“æŸè¿è¡Œ: {self.run_id}")
            self.current_run = None
            self.run_id = None
    
    def get_experiment_runs(self, 
                           max_results: int = 100,
                           order_by: Optional[List[str]] = None) -> List[Any]:
        """è·å–å®éªŒçš„æ‰€æœ‰è¿è¡Œ"""
        runs = self.client.search_runs(
            experiment_ids=[self.experiment_id],
            max_results=max_results,
            order_by=order_by or ["start_time DESC"]
        )
        return runs
    
    def get_best_run(self, metric: str, ascending: bool = False) -> Optional[Any]:
        """è·å–æœ€ä½³è¿è¡Œ"""
        runs = self.get_experiment_runs()
        
        if not runs:
            return None
        
        # è¿‡æ»¤æœ‰æŒ‡å®šæŒ‡æ ‡çš„è¿è¡Œ
        runs_with_metric = [run for run in runs if metric in run.data.metrics]
        
        if not runs_with_metric:
            return None
        
        # æŒ‰æŒ‡æ ‡æ’åº
        best_run = min(runs_with_metric, 
                      key=lambda r: r.data.metrics[metric] if not ascending 
                      else -r.data.metrics[metric])
        
        return best_run
    
    def compare_runs(self, run_ids: List[str]) -> Dict[str, Any]:
        """æ¯”è¾ƒå¤šä¸ªè¿è¡Œ"""
        runs_data = []
        
        for run_id in run_ids:
            run = self.client.get_run(run_id)
            runs_data.append({
                'run_id': run_id,
                'params': run.data.params,
                'metrics': run.data.metrics,
                'tags': run.data.tags,
                'status': run.info.status,
                'start_time': run.info.start_time,
                'end_time': run.info.end_time
            })
        
        return {
            'runs': runs_data,
            'comparison_time': datetime.now().isoformat()
        }
    
    def load_model(self, 
                   run_id: str, 
                   model_path: str = "model") -> Any:
        """åŠ è½½æ¨¡å‹"""
        model_uri = f"runs:/{run_id}/{model_path}"
        
        try:
            if TORCH_AVAILABLE:
                return mlflow.pytorch.load_model(model_uri)
            else:
                return mlflow.sklearn.load_model(model_uri)
        except Exception as e:
            logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def register_model(self, 
                      model_uri: str,
                      name: str,
                      description: Optional[str] = None,
                      tags: Optional[Dict[str, str]] = None) -> Any:
        """æ³¨å†Œæ¨¡å‹åˆ°æ¨¡å‹æ³¨å†Œè¡¨"""
        try:
            model_version = mlflow.register_model(
                model_uri=model_uri,
                name=name,
                tags=tags
            )
            
            if description:
                self.client.update_model_version(
                    name=name,
                    version=model_version.version,
                    description=description
                )
            
            logger.info(f"æ¨¡å‹å·²æ³¨å†Œ: {name} v{model_version.version}")
            return model_version
            
        except Exception as e:
            logger.error(f"æ³¨å†Œæ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def get_experiment_info(self) -> Dict[str, Any]:
        """è·å–å®éªŒä¿¡æ¯"""
        experiment = self.client.get_experiment(self.experiment_id)
        runs = self.get_experiment_runs()
        
        return {
            'experiment_id': self.experiment_id,
            'experiment_name': experiment.name,
            'artifact_location': experiment.artifact_location,
            'lifecycle_stage': experiment.lifecycle_stage,
            'total_runs': len(runs),
            'active_runs': len([r for r in runs if r.info.status == RunStatus.RUNNING]),
            'completed_runs': len([r for r in runs if r.info.status == RunStatus.FINISHED]),
            'failed_runs': len([r for r in runs if r.info.status == RunStatus.FAILED])
        }


def demo():
    """æ¼”ç¤ºMLflowè·Ÿè¸ªå™¨çš„ä½¿ç”¨"""
    if not MLFLOW_AVAILABLE:
        print("âŒ MLflowæœªå®‰è£…ï¼Œæ— æ³•è¿è¡Œæ¼”ç¤º")
        print("è¯·è¿è¡Œ: pip install mlflow")
        return
    
    print("ğŸš€ MLflowè·Ÿè¸ªå™¨æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºè·Ÿè¸ªå™¨
    tracker = MLflowTracker(
        experiment_name="demo_experiment",
        auto_log=False  # å…³é—­è‡ªåŠ¨æ—¥å¿—ä»¥ä¾¿æ¼”ç¤º
    )
    
    print(f"ğŸ“Š å®éªŒä¿¡æ¯:")
    exp_info = tracker.get_experiment_info()
    for key, value in exp_info.items():
        print(f"  {key}: {value}")
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    print("\nğŸ”§ æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹...")
    
    with tracker.start_run(run_name="demo_training") as t:
        # è®°å½•è¶…å‚æ•°
        params = {
            "learning_rate": 0.001,
            "batch_size": 32,
            "epochs": 10,
            "model_type": "transformer",
            "optimizer": "adam"
        }
        t.log_params(params)
        print("âœ… å·²è®°å½•è®­ç»ƒå‚æ•°")
        
        # è®¾ç½®æ ‡ç­¾
        tags = {
            "model_family": "transformer",
            "dataset": "demo_data",
            "stage": "stage4"
        }
        t.set_tags(tags)
        print("âœ… å·²è®¾ç½®è¿è¡Œæ ‡ç­¾")
        
        # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
        import random
        import time
        
        for epoch in range(5):  # ç®€åŒ–ä¸º5ä¸ªepoch
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
            train_loss = 2.0 - epoch * 0.3 + random.uniform(-0.1, 0.1)
            val_loss = 2.2 - epoch * 0.25 + random.uniform(-0.1, 0.1)
            
            train_metrics = {
                "accuracy": 0.5 + epoch * 0.08 + random.uniform(-0.02, 0.02),
                "bleu": 0.2 + epoch * 0.05 + random.uniform(-0.01, 0.01)
            }
            
            val_metrics = {
                "accuracy": 0.45 + epoch * 0.07 + random.uniform(-0.02, 0.02),
                "bleu": 0.18 + epoch * 0.04 + random.uniform(-0.01, 0.01)
            }
            
            # è®°å½•è®­ç»ƒè¿›åº¦
            t.log_training_progress(
                epoch=epoch,
                train_loss=train_loss,
                val_loss=val_loss,
                train_metrics=train_metrics,
                val_metrics=val_metrics
            )
            
            print(f"  Epoch {epoch}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}")
            time.sleep(0.1)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
        
        # è®°å½•æ–‡æœ¬ä¿¡æ¯
        training_log = f\"\"\"è®­ç»ƒå®Œæˆæ‘˜è¦:\n- æ€»epochs: 5\n- æœ€ç»ˆè®­ç»ƒæŸå¤±: {train_loss:.4f}\n- æœ€ç»ˆéªŒè¯æŸå¤±: {val_loss:.4f}\n- æœ€ç»ˆè®­ç»ƒå‡†ç¡®ç‡: {train_metrics['accuracy']:.4f}\n- æœ€ç»ˆéªŒè¯å‡†ç¡®ç‡: {val_metrics['accuracy']:.4f}\n\"\"\"
        
        t.log_text(training_log, "training_summary.txt")
        
        # è®°å½•é…ç½®å­—å…¸
        config_dict = {
            "model_config": {
                "d_model": 512,
                "num_heads": 8,
                "num_layers": 6,
                "d_ff": 2048
            },
            "training_config": params,
            "final_metrics": {
                "train": train_metrics,
                "val": val_metrics
            }
        }
        t.log_dict(config_dict, "experiment_config.json")
        
        print("âœ… è®­ç»ƒå®Œæˆï¼Œæ‰€æœ‰æ•°æ®å·²è®°å½•åˆ°MLflow")
    
    # è·å–å®éªŒè¿è¡Œ
    print("\nğŸ“‹ è·å–å®éªŒè¿è¡Œ...")
    runs = tracker.get_experiment_runs(max_results=5)
    
    print(f"æ‰¾åˆ° {len(runs)} ä¸ªè¿è¡Œ:")
    for run in runs[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
        print(f"  - Run ID: {run.info.run_id}")
        print(f"    çŠ¶æ€: {run.info.status}")
        print(f"    å¼€å§‹æ—¶é—´: {run.info.start_time}")
        if run.data.metrics:
            print(f"    æŒ‡æ ‡: {list(run.data.metrics.keys())}")
    
    # è·å–æœ€ä½³è¿è¡Œ
    print("\nğŸ† å¯»æ‰¾æœ€ä½³è¿è¡Œ...")
    best_run = tracker.get_best_run("val_loss", ascending=True)
    if best_run:
        print(f"æœ€ä½³è¿è¡Œ (æœ€ä½éªŒè¯æŸå¤±):")
        print(f"  - Run ID: {best_run.info.run_id}")
        print(f"  - éªŒè¯æŸå¤±: {best_run.data.metrics['val_loss']:.4f}")
        print(f"  - éªŒè¯å‡†ç¡®ç‡: {best_run.data.metrics.get('val_accuracy', 'N/A')}")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print("ğŸ’¡ å¯åŠ¨MLflow UIæŸ¥çœ‹ç»“æœ: mlflow ui")


if __name__ == "__main__":
    demo()