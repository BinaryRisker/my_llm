{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# 阶段1：MLP文本分类可视化分析\\n\",\n    \"\\n\",\n    \"这个notebook提供了对MLP文本分类模型的深入可视化分析，包括：\\n\",\n    \"- 训练过程分析\\n\",\n    \"- 模型性能评估\\n\",\n    \"- 错误分析\\n\",\n    \"- 词嵌入可视化\\n\",\n    \"- 注意力权重分析\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"import os\\n\",\n    \"import sys\\n\",\n    \"import json\\n\",\n    \"import numpy as np\\n\",\n    \"import pandas as pd\\n\",\n    \"import matplotlib.pyplot as plt\\n\",\n    \"import seaborn as sns\\n\",\n    \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n    \"from sklearn.decomposition import PCA\\n\",\n    \"from sklearn.manifold import TSNE\\n\",\n    \"import torch\\n\",\n    \"import torch.nn.functional as F\\n\",\n    \"\\n\",\n    \"# 设置项目路径\\n\",\n    \"sys.path.append('..')\\n\",\n    \"\\n\",\n    \"from models.mlp import SimpleMLP, MLPWithBagOfWords\\n\",\n    \"from utils.data_utils import TextVocabulary, load_ag_news_sample\\n\",\n    \"\\n\",\n    \"# 设置可视化样式\\n\",\n    \"plt.style.use('default')\\n\",\n    \"sns.set_palette(\\\"husl\\\")\\n\",\n    \"\\n\",\n    \"%matplotlib inline\\n\",\n    \"\\n\",\n    \"print(\\\"📊 导入完成！\\\")\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 1. 加载训练数据和模型\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 模型保存目录\\n\",\n    \"MODEL_DIR = './checkpoints'\\n\",\n    \"\\n\",\n    \"# 检查是否存在训练好的模型\\n\",\n    \"if not os.path.exists(MODEL_DIR):\\n\",\n    \"    print(\\\"❌ 未找到训练好的模型，请先运行 train.py\\\")\\n\",\n    \"    print(\\\"💡 运行: python train.py --epochs 10\\\")\\n\",\n    \"else:\\n\",\n    \"    print(f\\\"✅ 找到模型目录: {MODEL_DIR}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 加载配置文件\\n\",\n    \"try:\\n\",\n    \"    with open(os.path.join(MODEL_DIR, 'config.json'), 'r') as f:\\n\",\n    \"        config = json.load(f)\\n\",\n    \"    \\n\",\n    \"    with open(os.path.join(MODEL_DIR, 'training_summary.json'), 'r') as f:\\n\",\n    \"        training_summary = json.load(f)\\n\",\n    \"    \\n\",\n    \"    print(\\\"模型配置:\\\")\\n\",\n    \"    for key, value in config.items():\\n\",\n    \"        print(f\\\"  {key}: {value}\\\")\\n\",\n    \"    \\n\",\n    \"    print(f\\\"\\\\n最终训练性能:\\\")\\n\",\n    \"    print(f\\\"  训练准确率: {training_summary['final_train_acc']:.4f}\\\")\\n\",\n    \"    print(f\\\"  验证准确率: {training_summary['final_val_acc']:.4f}\\\")\\n\",\n    \"    print(f\\\"  最佳验证准确率: {training_summary['best_val_acc']:.4f}\\\")\\n\",\n    \"except Exception as e:\\n\",\n    \"    print(f\\\"❌ 加载配置失败: {e}\\\")\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 2. 训练过程可视化\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 绘制训练曲线\\n\",\n    \"def plot_training_curves(training_summary):\\n\",\n    \"    history = training_summary['train_history']\\n\",\n    \"    \\n\",\n    \"    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\\n\",\n    \"    \\n\",\n    \"    # 损失曲线\\n\",\n    \"    axes[0, 0].plot(history['train_losses'], label='训练损失', marker='o', markersize=4)\\n\",\n    \"    axes[0, 0].plot(history['val_losses'], label='验证损失', marker='s', markersize=4)\\n\",\n    \"    axes[0, 0].set_title('训练和验证损失')\\n\",\n    \"    axes[0, 0].set_xlabel('Epoch')\\n\",\n    \"    axes[0, 0].set_ylabel('Loss')\\n\",\n    \"    axes[0, 0].legend()\\n\",\n    \"    axes[0, 0].grid(True, alpha=0.3)\\n\",\n    \"    \\n\",\n    \"    # 准确率曲线\\n\",\n    \"    axes[0, 1].plot(history['train_accuracies'], label='训练准确率', marker='o', markersize=4)\\n\",\n    \"    axes[0, 1].plot(history['val_accuracies'], label='验证准确率', marker='s', markersize=4)\\n\",\n    \"    axes[0, 1].set_title('训练和验证准确率')\\n\",\n    \"    axes[0, 1].set_xlabel('Epoch')\\n\",\n    \"    axes[0, 1].set_ylabel('Accuracy')\\n\",\n    \"    axes[0, 1].legend()\\n\",\n    \"    axes[0, 1].grid(True, alpha=0.3)\\n\",\n    \"    \\n\",\n    \"    # 过拟合分析\\n\",\n    \"    train_val_diff = np.array(history['train_accuracies']) - np.array(history['val_accuracies'])\\n\",\n    \"    axes[1, 0].plot(train_val_diff, marker='d', color='red', markersize=4)\\n\",\n    \"    axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\\n\",\n    \"    axes[1, 0].set_title('训练-验证准确率差值（过拟合指标）')\\n\",\n    \"    axes[1, 0].set_xlabel('Epoch')\\n\",\n    \"    axes[1, 0].set_ylabel('Train Acc - Val Acc')\\n\",\n    \"    axes[1, 0].grid(True, alpha=0.3)\\n\",\n    \"    \\n\",\n    \"    # 学习速度分析\\n\",\n    \"    train_loss_diff = np.diff(history['train_losses'])\\n\",\n    \"    axes[1, 1].plot(train_loss_diff, marker='v', color='green', markersize=4)\\n\",\n    \"    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\\n\",\n    \"    axes[1, 1].set_title('训练损失变化率（学习速度）')\\n\",\n    \"    axes[1, 1].set_xlabel('Epoch')\\n\",\n    \"    axes[1, 1].set_ylabel('Loss Change')\\n\",\n    \"    axes[1, 1].grid(True, alpha=0.3)\\n\",\n    \"    \\n\",\n    \"    plt.tight_layout()\\n\",\n    \"    plt.show()\\n\",\n    \"\\n\",\n    \"plot_training_curves(training_summary)\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 3. 模型性能分析\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 加载模型和数据进行详细评估\\n\",\n    \"def load_model_and_data():\\n\",\n    \"    # 加载词汇表\\n\",\n    \"    vocab = TextVocabulary()\\n\",\n    \"    vocab.load(os.path.join(MODEL_DIR, 'vocabulary.pkl'))\\n\",\n    \"    \\n\",\n    \"    # 加载数据\\n\",\n    \"    texts, labels, class_names = load_ag_news_sample()\\n\",\n    \"    \\n\",\n    \"    # 分割数据（与训练时保持一致）\\n\",\n    \"    split_idx = int(0.8 * len(texts))\\n\",\n    \"    val_texts = texts[split_idx:]\\n\",\n    \"    val_labels = labels[split_idx:]\\n\",\n    \"    \\n\",\n    \"    # 加载模型\\n\",\n    \"    if config['model_type'] == 'embedding':\\n\",\n    \"        model = SimpleMLP(\\n\",\n    \"            vocab_size=config['vocab_size'],\\n\",\n    \"            embedding_dim=config['embedding_dim'],\\n\",\n    \"            hidden_dims=config['hidden_dims'],\\n\",\n    \"            num_classes=config['num_classes'],\\n\",\n    \"            dropout_rate=config['dropout']\\n\",\n    \"        )\\n\",\n    \"        checkpoint_path = os.path.join(MODEL_DIR, 'best_embedding_mlp.pt')\\n\",\n    \"    else:\\n\",\n    \"        model = MLPWithBagOfWords(\\n\",\n    \"            vocab_size=config['vocab_size'],\\n\",\n    \"            hidden_dims=config['hidden_dims'],\\n\",\n    \"            num_classes=config['num_classes'],\\n\",\n    \"            dropout_rate=config['dropout']\\n\",\n    \"        )\\n\",\n    \"        checkpoint_path = os.path.join(MODEL_DIR, 'best_bow_mlp.pt')\\n\",\n    \"    \\n\",\n    \"    # 加载训练好的权重\\n\",\n    \"    checkpoint = torch.load(checkpoint_path, map_location='cpu')\\n\",\n    \"    model.load_state_dict(checkpoint['model_state_dict'])\\n\",\n    \"    model.eval()\\n\",\n    \"    \\n\",\n    \"    return model, vocab, val_texts, val_labels, class_names\\n\",\n    \"\\n\",\n    \"model, vocab, val_texts, val_labels, class_names = load_model_and_data()\\n\",\n    \"print(f\\\"✅ 加载完成: {len(val_texts)} 个验证样本\\\")\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 生成预测结果\\n\",\n    \"def generate_predictions(model, vocab, texts, config):\\n\",\n    \"    predictions = []\\n\",\n    \"    probabilities = []\\n\",\n    \"    \\n\",\n    \"    model.eval()\\n\",\n    \"    with torch.no_grad():\\n\",\n    \"        for text in texts:\\n\",\n    \"            if config['model_type'] == 'embedding':\\n\",\n    \"                # 预处理\\n\",\n    \"                indices = vocab.text_to_indices(text, config['max_length'])\\n\",\n    \"                mask = [1 if i != vocab.token2idx[vocab.PAD_TOKEN] else 0 for i in indices]\\n\",\n    \"                \\n\",\n    \"                # 转换为张量\\n\",\n    \"                input_tensor = torch.tensor([indices], dtype=torch.long)\\n\",\n    \"                mask_tensor = torch.tensor([mask], dtype=torch.long)\\n\",\n    \"                \\n\",\n    \"                # 预测\\n\",\n    \"                logits = model(input_tensor, mask_tensor)\\n\",\n    \"            else:\\n\",\n    \"                # Bag-of-words处理\\n\",\n    \"                tokens = vocab.tokenize(text)\\n\",\n    \"                bow_vector = torch.zeros(len(vocab), dtype=torch.float)\\n\",\n    \"                for token in tokens:\\n\",\n    \"                    idx = vocab.token2idx.get(token, vocab.token2idx[vocab.UNK_TOKEN])\\n\",\n    \"                    bow_vector[idx] += 1.0\\n\",\n    \"                \\n\",\n    \"                input_tensor = bow_vector.unsqueeze(0)\\n\",\n    \"                logits = model(input_tensor)\\n\",\n    \"            \\n\",\n    \"            probs = F.softmax(logits, dim=-1)\\n\",\n    \"            pred = torch.argmax(probs, dim=-1).item()\\n\",\n    \"            \\n\",\n    \"            predictions.append(pred)\\n\",\n    \"            probabilities.append(probs.numpy()[0])\\n\",\n    \"    \\n\",\n    \"    return predictions, probabilities\\n\",\n    \"\\n\",\n    \"val_predictions, val_probabilities = generate_predictions(model, vocab, val_texts, config)\\n\",\n    \"print(f\\\"✅ 生成了 {len(val_predictions)} 个预测结果\\\")\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 绘制混淆矩阵\\n\",\n    \"def plot_confusion_matrix(y_true, y_pred, class_names):\\n\",\n    \"    cm = confusion_matrix(y_true, y_pred)\\n\",\n    \"    \\n\",\n    \"    plt.figure(figsize=(10, 8))\\n\",\n    \"    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\\n\",\n    \"                xticklabels=class_names, yticklabels=class_names)\\n\",\n    \"    plt.title('混淆矩阵', fontsize=16)\\n\",\n    \"    plt.xlabel('预测类别', fontsize=12)\\n\",\n    \"    plt.ylabel('真实类别', fontsize=12)\\n\",\n    \"    \\n\",\n    \"    # 添加准确率标注\\n\",\n    \"    accuracy = np.diag(cm) / np.sum(cm, axis=1)\\n\",\n    \"    for i, acc in enumerate(accuracy):\\n\",\n    \"        plt.text(len(class_names) + 0.1, i + 0.5, f'准确率: {acc:.3f}', \\n\",\n    \"                verticalalignment='center')\\n\",\n    \"    \\n\",\n    \"    plt.tight_layout()\\n\",\n    \"    plt.show()\\n\",\n    \"    \\n\",\n    \"    return cm\\n\",\n    \"\\n\",\n    \"cm = plot_confusion_matrix(val_labels, val_predictions, class_names)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 详细分类报告\\n\",\n    \"print(\\\"📊 详细分类报告:\\\")\\n\",\n    \"print(classification_report(val_labels, val_predictions, target_names=class_names))\\n\",\n    \"\\n\",\n    \"# 计算各类别的准确率\\n\",\n    \"class_accuracy = np.diag(cm) / np.sum(cm, axis=1)\\n\",\n    \"\\n\",\n    \"print(\\\"\\\\n📈 各类别准确率:\\\")\\n\",\n    \"for i, (name, acc) in enumerate(zip(class_names, class_accuracy)):\\n\",\n    \"    print(f\\\"  {name}: {acc:.4f}\\\")\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 4. 预测置信度分析\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 分析预测置信度\\n\",\n    \"def analyze_prediction_confidence(probabilities, predictions, true_labels, class_names):\\n\",\n    \"    # 计算最大概率（置信度）\\n\",\n    \"    confidences = [prob[pred] for prob, pred in zip(probabilities, predictions)]\\n\",\n    \"    \\n\",\n    \"    # 判断预测是否正确\\n\",\n    \"    correct = [pred == true for pred, true in zip(predictions, true_labels)]\\n\",\n    \"    \\n\",\n    \"    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\\n\",\n    \"    \\n\",\n    \"    # 1. 置信度分布\\n\",\n    \"    axes[0].hist([conf for conf, corr in zip(confidences, correct) if corr], \\n\",\n    \"                alpha=0.7, bins=20, label='正确预测', color='green')\\n\",\n    \"    axes[0].hist([conf for conf, corr in zip(confidences, correct) if not corr], \\n\",\n    \"                alpha=0.7, bins=20, label='错误预测', color='red')\\n\",\n    \"    axes[0].set_title('预测置信度分布')\\n\",\n    \"    axes[0].set_xlabel('置信度')\\n\",\n    \"    axes[0].set_ylabel('频次')\\n\",\n    \"    axes[0].legend()\\n\",\n    \"    \\n\",\n    \"    # 2. 置信度vs准确率\\n\",\n    \"    confidence_bins = np.linspace(0.25, 1.0, 10)\\n\",\n    \"    bin_accuracy = []\\n\",\n    \"    bin_counts = []\\n\",\n    \"    \\n\",\n    \"    for i in range(len(confidence_bins)-1):\\n\",\n    \"        mask = (np.array(confidences) >= confidence_bins[i]) & (np.array(confidences) < confidence_bins[i+1])\\n\",\n    \"        if mask.sum() > 0:\\n\",\n    \"            acc = np.array(correct)[mask].mean()\\n\",\n    \"            count = mask.sum()\\n\",\n    \"        else:\\n\",\n    \"            acc = 0\\n\",\n    \"            count = 0\\n\",\n    \"        bin_accuracy.append(acc)\\n\",\n    \"        bin_counts.append(count)\\n\",\n    \"    \\n\",\n    \"    bin_centers = (confidence_bins[:-1] + confidence_bins[1:]) / 2\\n\",\n    \"    axes[1].bar(bin_centers, bin_accuracy, width=0.08, alpha=0.7)\\n\",\n    \"    axes[1].plot([0.25, 1.0], [0.25, 1.0], 'r--', alpha=0.5, label='理想校准')\\n\",\n    \"    axes[1].set_title('置信度校准曲线')\\n\",\n    \"    axes[1].set_xlabel('预测置信度')\\n\",\n    \"    axes[1].set_ylabel('实际准确率')\\n\",\n    \"    axes[1].legend()\\n\",\n    \"    \\n\",\n    \"    # 3. 各类别平均置信度\\n\",\n    \"    class_confidences = []\\n\",\n    \"    for class_idx in range(len(class_names)):\\n\",\n    \"        class_mask = np.array(predictions) == class_idx\\n\",\n    \"        if class_mask.sum() > 0:\\n\",\n    \"            avg_conf = np.array(confidences)[class_mask].mean()\\n\",\n    \"        else:\\n\",\n    \"            avg_conf = 0\\n\",\n    \"        class_confidences.append(avg_conf)\\n\",\n    \"    \\n\",\n    \"    axes[2].bar(range(len(class_names)), class_confidences, alpha=0.7)\\n\",\n    \"    axes[2].set_title('各类别平均置信度')\\n\",\n    \"    axes[2].set_xlabel('类别')\\n\",\n    \"    axes[2].set_ylabel('平均置信度')\\n\",\n    \"    axes[2].set_xticks(range(len(class_names)))\\n\",\n    \"    axes[2].set_xticklabels(class_names, rotation=45)\\n\",\n    \"    \\n\",\n    \"    plt.tight_layout()\\n\",\n    \"    plt.show()\\n\",\n    \"    \\n\",\n    \"    # 打印统计信息\\n\",\n    \"    print(f\\\"平均置信度: {np.mean(confidences):.4f}\\\")\\n\",\n    \"    print(f\\\"正确预测平均置信度: {np.mean([c for c, corr in zip(confidences, correct) if corr]):.4f}\\\")\\n\",\n    \"    print(f\\\"错误预测平均置信度: {np.mean([c for c, corr in zip(confidences, correct) if not corr]):.4f}\\\")\\n\",\n    \"\\n\",\n    \"analyze_prediction_confidence(val_probabilities, val_predictions, val_labels, class_names)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 5. 错误案例分析\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 分析错误预测案例\\n\",\n    \"def analyze_errors(texts, true_labels, predictions, probabilities, class_names):\\n\",\n    \"    errors = []\\n\",\n    \"    \\n\",\n    \"    for i, (text, true_label, pred_label, prob) in enumerate(zip(texts, true_labels, predictions, probabilities)):\\n\",\n    \"        if true_label != pred_label:\\n\",\n    \"            confidence = prob[pred_label]\\n\",\n    \"            true_prob = prob[true_label]\\n\",\n    \"            errors.append({\\n\",\n    \"                'index': i,\\n\",\n    \"                'text': text,\\n\",\n    \"                'true_label': true_label,\\n\",\n    \"                'true_class': class_names[true_label],\\n\",\n    \"                'pred_label': pred_label,\\n\",\n    \"                'pred_class': class_names[pred_label],\\n\",\n    \"                'confidence': confidence,\\n\",\n    \"                'true_prob': true_prob,\\n\",\n    \"                'prob_diff': confidence - true_prob\\n\",\n    \"            })\\n\",\n    \"    \\n\",\n    \"    # 按置信度排序\\n\",\n    \"    errors.sort(key=lambda x: x['confidence'], reverse=True)\\n\",\n    \"    \\n\",\n    \"    print(f\\\"🔍 发现 {len(errors)} 个错误预测案例\\\\n\\\")\\n\",\n    \"    \\n\",\n    \"    # 显示高置信度错误案例\\n\",\n    \"    print(\\\"❌ 高置信度错误预测（模型很确信但是错误的）:\\\")\\n\",\n    \"    for i, error in enumerate(errors[:3]):\\n\",\n    \"        print(f\\\"\\\\n{i+1}. 文本: {error['text']}\\\")\\n\",\n    \"        print(f\\\"   真实类别: {error['true_class']} (概率: {error['true_prob']:.4f})\\\")\\n\",\n    \"        print(f\\\"   预测类别: {error['pred_class']} (置信度: {error['confidence']:.4f})\\\")\\n\",\n    \"    \\n\",\n    \"    # 显示低置信度错误案例\\n\",\n    \"    print(\\\"\\\\n🤔 低置信度错误预测（模型不确定且错误）:\\\")\\n\",\n    \"    for i, error in enumerate(errors[-3:]):\\n\",\n    \"        print(f\\\"\\\\n{i+1}. 文本: {error['text']}\\\")\\n\",\n    \"        print(f\\\"   真实类别: {error['true_class']} (概率: {error['true_prob']:.4f})\\\")\\n\",\n    \"        print(f\\\"   预测类别: {error['pred_class']} (置信度: {error['confidence']:.4f})\\\")\\n\",\n    \"    \\n\",\n    \"    return errors\\n\",\n    \"\\n\",\n    \"errors = analyze_errors(val_texts, val_labels, val_predictions, val_probabilities, class_names)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 6. 词嵌入可视化（仅适用于Embedding模型）\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 词嵌入可视化\\n\",\n    \"def visualize_embeddings(model, vocab, config, num_words=50):\\n\",\n    \"    if config['model_type'] != 'embedding':\\n\",\n    \"        print(\\\"⚠️ 当前模型类型不支持词嵌入可视化\\\")\\n\",\n    \"        return\\n\",\n    \"    \\n\",\n    \"    # 提取嵌入层权重\\n\",\n    \"    embeddings = model.embedding.weight.data.numpy()\\n\",\n    \"    \\n\",\n    \"    # 选择最频繁的词汇进行可视化\\n\",\n    \"    word_indices = list(range(4, min(len(vocab), num_words + 4)))  # 跳过特殊token\\n\",\n    \"    word_embeddings = embeddings[word_indices]\\n\",\n    \"    words = [vocab.idx2token[idx] for idx in word_indices]\\n\",\n    \"    \\n\",\n    \"    # 使用t-SNE进行降维\\n\",\n    \"    print(\\\"🔄 正在进行t-SNE降维...\\\")\\n\",\n    \"    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(words)-1))\\n\",\n    \"    embeddings_2d = tsne.fit_transform(word_embeddings)\\n\",\n    \"    \\n\",\n    \"    # 绘制散点图\\n\",\n    \"    plt.figure(figsize=(12, 8))\\n\",\n    \"    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], alpha=0.7, s=60)\\n\",\n    \"    \\n\",\n    \"    # 添加词汇标签\\n\",\n    \"    for i, word in enumerate(words):\\n\",\n    \"        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]), \\n\",\n    \"                    xytext=(5, 5), textcoords='offset points', \\n\",\n    \"                    fontsize=8, alpha=0.8)\\n\",\n    \"    \\n\",\n    \"    plt.title('词嵌入t-SNE可视化', fontsize=16)\\n\",\n    \"    plt.xlabel('t-SNE 维度 1')\\n\",\n    \"    plt.ylabel('t-SNE 维度 2')\\n\",\n    \"    plt.grid(True, alpha=0.3)\\n\",\n    \"    plt.tight_layout()\\n\",\n    \"    plt.show()\\n\",\n    \"    \\n\",\n    \"    # PCA降维对比\\n\",\n    \"    pca = PCA(n_components=2)\\n\",\n    \"    embeddings_pca = pca.fit_transform(word_embeddings)\\n\",\n    \"    \\n\",\n    \"    plt.figure(figsize=(12, 8))\\n\",\n    \"    plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1], alpha=0.7, s=60)\\n\",\n    \"    \\n\",\n    \"    for i, word in enumerate(words):\\n\",\n    \"        plt.annotate(word, (embeddings_pca[i, 0], embeddings_pca[i, 1]), \\n\",\n    \"                    xytext=(5, 5), textcoords='offset points', \\n\",\n    \"                    fontsize=8, alpha=0.8)\\n\",\n    \"    \\n\",\n    \"    plt.title('词嵌入PCA可视化', fontsize=16)\\n\",\n    \"    plt.xlabel(f'PC1 (解释方差: {pca.explained_variance_ratio_[0]:.3f})')\\n\",\n    \"    plt.ylabel(f'PC2 (解释方差: {pca.explained_variance_ratio_[1]:.3f})')\\n\",\n    \"    plt.grid(True, alpha=0.3)\\n\",\n    \"    plt.tight_layout()\\n\",\n    \"    plt.show()\\n\",\n    \"\\n\",\n    \"visualize_embeddings(model, vocab, config)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 7. 模型性能总结\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 生成完整的性能报告\\n\",\n    \"def generate_performance_report(config, training_summary, val_labels, val_predictions, errors):\\n\",\n    \"    print(\\\"📋 模型性能总结报告\\\")\\n\",\n    \"    print(\\\"=\\\" * 50)\\n\",\n    \"    \\n\",\n    \"    # 模型基本信息\\n\",\n    \"    print(f\\\"🏗️ 模型类型: {config['model_type']}\\\")\\n\",\n    \"    if config['model_type'] == 'embedding':\\n\",\n    \"        print(f\\\"📊 嵌入维度: {config['embedding_dim']}\\\")\\n\",\n    \"    print(f\\\"🧠 隐藏层: {config['hidden_dims']}\\\")\\n\",\n    \"    print(f\\\"📚 词汇表大小: {config['vocab_size']}\\\")\\n\",\n    \"    print(f\\\"🎯 类别数: {config['num_classes']}\\\")\\n\",\n    \"    \\n\",\n    \"    # 训练性能\\n\",\n    \"    print(f\\\"\\\\n🏃 训练性能:\\\")\\n\",\n    \"    print(f\\\"   最终训练准确率: {training_summary['final_train_acc']:.4f}\\\")\\n\",\n    \"    print(f\\\"   最终验证准确率: {training_summary['final_val_acc']:.4f}\\\")\\n\",\n    \"    print(f\\\"   最佳验证准确率: {training_summary['best_val_acc']:.4f}\\\")\\n\",\n    \"    \\n\",\n    \"    # 验证集详细性能\\n\",\n    \"    val_accuracy = sum(pred == true for pred, true in zip(val_predictions, val_labels)) / len(val_labels)\\n\",\n    \"    print(f\\\"\\\\n✅ 验证集性能:\\\")\\n\",\n    \"    print(f\\\"   准确率: {val_accuracy:.4f}\\\")\\n\",\n    \"    print(f\\\"   错误预测数: {len(errors)} / {len(val_labels)}\\\")\\n\",\n    \"    \\n\",\n    \"    # 过拟合分析\\n\",\n    \"    overfitting = training_summary['final_train_acc'] - training_summary['final_val_acc']\\n\",\n    \"    print(f\\\"\\\\n🔍 过拟合分析:\\\")\\n\",\n    \"    print(f\\\"   训练-验证准确率差值: {overfitting:.4f}\\\")\\n\",\n    \"    if overfitting > 0.1:\\n\",\n    \"        print(f\\\"   ⚠️ 存在过拟合现象，建议增加正则化或减少模型复杂度\\\")\\n\",\n    \"    elif overfitting < 0:\\n\",\n    \"        print(f\\\"   ⚠️ 验证准确率高于训练准确率，可能存在数据泄露或样本不足\\\")\\n\",\n    \"    else:\\n\",\n    \"        print(f\\\"   ✅ 模型泛化良好\\\")\\n\",\n    \"    \\n\",\n    \"    # 改进建议\\n\",\n    \"    print(f\\\"\\\\n💡 改进建议:\\\")\\n\",\n    \"    if val_accuracy < 0.7:\\n\",\n    \"        print(f\\\"   - 准确率较低，建议增加模型复杂度或更多训练数据\\\")\\n\",\n    \"    if len(errors) > len(val_labels) * 0.3:\\n\",\n    \"        print(f\\\"   - 错误率较高，检查数据质量和预处理流程\\\")\\n\",\n    \"    if overfitting > 0.1:\\n\",\n    \"        print(f\\\"   - 增加Dropout率或使用其他正则化技术\\\")\\n\",\n    \"        print(f\\\"   - 收集更多训练数据\\\")\\n\",\n    \"    if config['model_type'] == 'bow' and val_accuracy < 0.8:\\n\",\n    \"        print(f\\\"   - 考虑使用embedding模型获得更好的性能\\\")\\n\",\n    \"    \\n\",\n    \"generate_performance_report(config, training_summary, val_labels, val_predictions, errors)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 8. 交互式预测测试\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"source\": [\n    \"# 交互式测试新文本\\n\",\n    \"def predict_new_text(text, model, vocab, config, class_names):\\n\",\n    \"    model.eval()\\n\",\n    \"    with torch.no_grad():\\n\",\n    \"        if config['model_type'] == 'embedding':\\n\",\n    \"            indices = vocab.text_to_indices(text, config['max_length'])\\n\",\n    \"            mask = [1 if i != vocab.token2idx[vocab.PAD_TOKEN] else 0 for i in indices]\\n\",\n    \"            \\n\",\n    \"            input_tensor = torch.tensor([indices], dtype=torch.long)\\n\",\n    \"            mask_tensor = torch.tensor([mask], dtype=torch.long)\\n\",\n    \"            \\n\",\n    \"            logits = model(input_tensor, mask_tensor)\\n\",\n    \"        else:\\n\",\n    \"            tokens = vocab.tokenize(text)\\n\",\n    \"            bow_vector = torch.zeros(len(vocab), dtype=torch.float)\\n\",\n    \"            for token in tokens:\\n\",\n    \"                idx = vocab.token2idx.get(token, vocab.token2idx[vocab.UNK_TOKEN])\\n\",\n    \"                bow_vector[idx] += 1.0\\n\",\n    \"            \\n\",\n    \"            input_tensor = bow_vector.unsqueeze(0)\\n\",\n    \"            logits = model(input_tensor)\\n\",\n    \"        \\n\",\n    \"        probabilities = F.softmax(logits, dim=-1).numpy()[0]\\n\",\n    \"        predicted_class = np.argmax(probabilities)\\n\",\n    \"        confidence = probabilities[predicted_class]\\n\",\n    \"    \\n\",\n    \"    print(f\\\"📝 输入文本: {text}\\\")\\n\",\n    \"    print(f\\\"🎯 预测类别: {class_names[predicted_class]} (置信度: {confidence:.4f})\\\")\\n\",\n    \"    print(f\\\"📊 所有类别概率:\\\")\\n\",\n    \"    for i, (prob, name) in enumerate(zip(probabilities, class_names)):\\n\",\n    \"        print(f\\\"   {name}: {prob:.4f}\\\")\\n\",\n    \"    \\n\",\n    \"    return predicted_class, confidence, probabilities\\n\",\n    \"\\n\",\n    \"# 测试一些示例\\n\",\n    \"test_texts = [\\n\",\n    \"    \\\"Apple releases new iPhone with amazing camera\\\",\\n\",\n    \"    \\\"Stock market crashes due to economic uncertainty\\\",\\n\",\n    \"    \\\"Scientists discover new planet in distant galaxy\\\",\\n\",\n    \"    \\\"Basketball team wins championship after thrilling game\\\"\\n\",\n    \"]\\n\",\n    \"\\n\",\n    \"print(\\\"🧪 测试新文本预测:\\\")\\n\",\n    \"print(\\\"=\\\" * 60)\\n\",\n    \"for i, text in enumerate(test_texts, 1):\\n\",\n    \"    print(f\\\"\\\\n测试 {i}:\\\")\\n\",\n    \"    predict_new_text(text, model, vocab, config, class_names)\\n\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## 结论\\n\",\n    \"\\n\",\n    \"通过这个详细的分析，您应该能够：\\n\",\n    \"\\n\",\n    \"1. **理解模型性能**: 通过训练曲线和混淆矩阵了解模型的优缺点\\n\",\n    \"2. **识别问题**: 通过错误案例分析找到模型的薄弱环节\\n\",\n    \"3. **可视化理解**: 通过词嵌入可视化理解模型学到的语义表示\\n\",\n    \"4. **改进方向**: 基于分析结果确定下一步改进策略\\n\",\n    \"\\n\",\n    \"### 下一步学习建议\\n\",\n    \"\\n\",\n    \"- 尝试不同的超参数设置\\n\",\n    \"- 使用更大的数据集\\n\",\n    \"- 进入阶段2学习RNN/LSTM处理序列数据\\n\",\n    \"- 探索更高级的文本表示方法\\n\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.5\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}